{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to group3docs","text":"<p>This is a simple documentation site.</p>"},{"location":"example-markdown/","title":"Examples for MkDocs","text":"Function to add two numbers<pre><code>def add_two_numbers(num1, num2):\n    return num1 + num2\n</code></pre>"},{"location":"example-markdown/#code-blocks-in-content-tabs","title":"Code Blocks in Content Tabs","text":"PythonJavaScript <pre><code>def main():\n    print(\"Hello world!\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>function main() {\n    console.log(\"Hello world!\");\n}\n\nmain();\n</code></pre>"},{"location":"example-markdown/#admonitions","title":"Admonitions","text":"<p>Title of the callout</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Collapsible callout:</p> Collapsible callout <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>For full documentation visit mkdocs.org.</p>"},{"location":"example-markdown/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"example-markdown/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"game-ideas/","title":"COMP5531 Group Project Game Ideas","text":"<p>Author</p> <p>Zach 01/02/25</p>"},{"location":"game-ideas/#game-genre-3rd-person-adventure","title":"Game Genre: 3rd person adventure","text":""},{"location":"game-ideas/#game-engine-requirements","title":"Game engine requirements:","text":"<ul> <li> <p>Cutscene handling (video/ actual scene)</p> </li> <li> <p>Game pausing</p> </li> <li> <p>Minimal AI with pathfinding (AI on rails)</p> </li> <li> <p>Good movement physics, jumping vaulting</p> </li> <li> <p>Skeletal animation (layered)</p> </li> <li> <p>Inverse kinematics for hand grabbing and feet</p> </li> <li> <p>Particle system, screenspace effects</p> </li> <li> <p>UI (and dialogue UI)</p> </li> <li> <p>A menu screen</p> </li> <li> <p>3d sound system</p> </li> <li> <p>Camera system (control, switching)</p> </li> <li> <p>Input handling (proper ie controller)</p> </li> </ul>"},{"location":"game-ideas/#subgenre-obby-platformer","title":"Subgenre: obby platformer","text":"<p>Inspo games:</p> <ul> <li> <p>Only up https://www.youtube.com/watch?v=bVFsHqvaI70</p> </li> <li> <p>Roblox tower obby https://www.youtube.com/watch?v=o3vl_supQ14</p> </li> </ul> <p>Game idea: Tower obby with rising water, if you touch water you die.</p> <p>Minimum viable product: One tower with objects to jump and climb up with start at bottom and end at top.</p>"},{"location":"game-ideas/#subgenre-stealth","title":"Subgenre: stealth","text":"<p>Inspo games:</p> <ul> <li> <p>We happy few https://www.youtube.com/watch?v=R6kIvK5ARqU</p> </li> <li> <p>Indika https://youtu.be/6ggFbiA0zOg?si=iiZtkv9f_rhZK3nQ</p> </li> </ul> <p>Game idea: In a map, get from A to B without getting caught by the enemy, press x to reveal who is the enemy and highlight their sightlines.</p> <p>Minimum viable product: One level with start and end point, with AI NPCs.</p>"},{"location":"game-ideas/#subgenre-platformer-puzzle","title":"Subgenre: platformer puzzle","text":"<p>Inspo games:</p> <ul> <li>Watchdogs https://www.youtube.com/watch?v=pedilCYcCYQ</li> </ul> <p>Game idea: In a map get from A to B, you can hack cameras to see from their POV and can teleport to where the camera is looking at.</p> <p>Minimum viable product: One level with start and end, several cameras to show mechanic.</p>"},{"location":"game-ideas/#subgenre-stealthadventuresimulator","title":"Subgenre: stealth/adventure/simulator","text":"<p>Inspo games:</p> <ul> <li> <p>GTA https://www.youtube.com/watch?v=7ssp44DydyA</p> </li> <li> <p>Detroit Become human https://www.youtube.com/watch?v=JVywqFx0GdE</p> </li> <li> <p>Watch dogs (again) https://www.youtube.com/watch?v=pedilCYcCYQ</p> </li> </ul> <p>Game idea: You work in a strip club, work your shift and scam cheat and steal as much money from the men as possible.</p> <p>Minimum viable product: One day/shift, several NPCs to steal from.</p>"},{"location":"gltf/","title":"glTF Discussion","text":""},{"location":"gltf/#what-is-gltf","title":"What is glTF?","text":"<p>glTF is a file format for scenes and models and will let us not worry about figuring out a good file format for our scene / scene graph (Real-Time Rendering 4th ed., 19.1.5 Scene Graphs).</p> <p>https://registry.khronos.org/glTF/specs/2.0/glTF-2.0.html#gltf-basic</p> <p>A glTF asset is represented by:</p> <ul> <li> <p>A JSON-formatted file (<code>.gltf</code>) containing a full scene description: node hierarchy, materials, cameras, as well as descriptor information for meshes, animations, and other constructs.</p> </li> <li> <p>Binary files (<code>.bin</code>) containing geometry, animation, and other buffer-based data.</p> </li> <li> <p>Image files (<code>.jpg</code>, <code>.png</code>) containing texture images.</p> </li> </ul> <p>Binary and image resources MAY also be embedded directly in JSON using Data URI or stored side-by-side with JSON in GLB container.</p>"},{"location":"gltf/#gltf-specific-loader-assimp","title":"glTF specific loader / assimp?","text":"<p>In this section, I'm going to explain why I think using a glTF specific file loader, cgltf, will be a better choice than using assimp. I'll motivate my choice of cgtlf over another glTF loader in the cgltf / fastgltf? section.</p> <p>In my opinion, we need to dedicate ourselves to the glTF format and not worry about other file formats. We can still load individual files with another loader, maybe a dedicated obj loader for example.</p> <p>As such, we should look for APIs which keep us as close to the glTF format as possible. It will help us understand what we're loading in and what we're writing out. Especially when eventually we have the ability to edit scenes using our engine. This is the main benefit of cgltf over assimp.</p>"},{"location":"gltf/#api-comparison","title":"API comparison","text":""},{"location":"gltf/#the-json-structure-of-gltf","title":"The JSON structure of glTF","text":"<p>This is the general structure we are trying to match.</p> <p> https://github.khronos.org/glTF-Tutorials/gltfTutorial/gltfTutorial_002_BasicGltfStructure.html</p>"},{"location":"gltf/#cgltf-api","title":"cgltf API","text":"<p>https://github.com/jkuhlmann/cgltf/blob/master/cgltf.h</p> <p><code>cgltf_data</code> is the struct allocated and filled by <code>cgltf_parse()</code>. It generally mirrors the glTF format as described by the spec (see https://github.com/KhronosGroup/glTF/tree/master/specification/2.0).)</p> <p>We can see how closely <code>cgltf_data</code> matches the glTF format:</p> <pre><code>typedef struct cgltf_data\n{\n    cgltf_file_type file_type;\n    void* file_data;\n\n    cgltf_asset asset;\n\n    cgltf_mesh* meshes;\n    cgltf_size meshes_count;\n\n    cgltf_material* materials;\n    cgltf_size materials_count;\n\n    cgltf_accessor* accessors;\n    cgltf_size accessors_count;\n\n    cgltf_buffer_view* buffer_views;\n    cgltf_size buffer_views_count;\n\n    cgltf_buffer* buffers;\n    cgltf_size buffers_count;\n\n    cgltf_image* images;\n    cgltf_size images_count;\n\n    cgltf_texture* textures;\n    cgltf_size textures_count;\n\n    cgltf_sampler* samplers;\n    cgltf_size samplers_count;\n\n    cgltf_skin* skins;\n    cgltf_size skins_count;\n\n    cgltf_camera* cameras;\n    cgltf_size cameras_count;\n\n    cgltf_light* lights;\n    cgltf_size lights_count;\n\n    cgltf_node* nodes;\n    cgltf_size nodes_count;\n\n    cgltf_scene* scenes;\n    cgltf_size scenes_count;\n\n    cgltf_scene* scene;\n\n    cgltf_animation* animations;\n    cgltf_size animations_count;\n\n    /* ... */\n} cgltf_data;\n</code></pre> <pre><code>struct cgltf_node {\n    char* name;\n    cgltf_node* parent;\n    cgltf_node** children;\n    cgltf_size children_count;\n    cgltf_skin* skin;\n    cgltf_mesh* mesh;\n    cgltf_camera* camera;\n    cgltf_light* light;\n    cgltf_float* weights;\n    cgltf_size weights_count;\n    cgltf_bool has_translation;\n    cgltf_bool has_rotation;\n    cgltf_bool has_scale;\n    cgltf_bool has_matrix;\n    cgltf_float translation[3];\n    cgltf_float rotation[4];\n    cgltf_float scale[3];\n    cgltf_float matrix[16];\n    cgltf_extras extras;\n    cgltf_bool has_mesh_gpu_instancing;\n    cgltf_mesh_gpu_instancing mesh_gpu_instancing;\n    cgltf_size extensions_count;\n    cgltf_extension* extensions;\n};\n</code></pre>"},{"location":"gltf/#assimp-api","title":"assimp API","text":"<p>https://github.com/assimp/assimp/blob/master/include/assimp/scene.h</p> <p>Whereas the assimp API is obviously a little bit futher away...</p> <pre><code>struct ASSIMP_API aiScene {\n    unsigned int mFlags;\n\n    C_STRUCT aiNode* mRootNode;\n\n    unsigned int mNumMeshes;\n    C_STRUCT aiMesh** mMeshes;\n\n    unsigned int mNumMaterials;\n    C_STRUCT aiMaterial** mMaterials;\n\n    unsigned int mNumAnimations;\n    C_STRUCT aiAnimation** mAnimations;\n\n    unsigned int mNumTextures;\n    C_STRUCT aiTexture** mTextures;\n\n    unsigned int mNumLights;\n    C_STRUCT aiLight** mLights;\n\n    unsigned int mNumCameras;\n    C_STRUCT aiCamera** mCameras;\n\n    C_STRUCT aiMetadata* mMetaData;\n\n    C_STRUCT aiString mName;\n\n    unsigned int mNumSkeletons;\n    C_STRUCT aiSkeleton **mSkeletons;\n\n    /* ... */\n};\n</code></pre> <pre><code>struct ASSIMP_API aiNode {\n    C_STRUCT aiString mName;\n\n    C_STRUCT aiMatrix4x4 mTransformation;\n\n    C_STRUCT aiNode* mParent;\n\n    unsigned int mNumChildren;\n    C_STRUCT aiNode** mChildren;\n\n    unsigned int mNumMeshes;\n    unsigned int* mMeshes;\n\n    /* ... */\n};\n</code></pre>"},{"location":"gltf/#cgltf-fastgltf","title":"cgltf / fastgltf?","text":""},{"location":"gltf/#features-comparison","title":"Features comparison","text":"<p>My main reason for wanting to use cgltf over fastgltf is the following comparison table. You can see that fastgltf does not support image decoding, which is probably something we would like to use.</p> <p>https://fastgltf.readthedocs.io/latest/overview.html</p> Feature cgltf tinygltf fastgltf glTF 2.0 reading \u2705 \u2705 \u2705 glTF 2.0 writing \u2705 \u2705 \u2705 Extension support \u2705 \ud83d\udfe7\u00b9 \u2705 Image decoding (PNG, JPEG, \u2026) \u2705 \u2705 \u274c Built-in Draco decompression \u274c \u2705 \u274c Memory callbacks \u2705 \u274c \ud83d\udfe7\u00b2 Android asset functionality \u274c \u2705 \u2705 Accessor utilities \u2705 \u274c \u2705 Sparse accessor utilities \ud83d\udfe7\u00b3 \u274c \u2705 Matrix accessor utilities \ud83d\udfe7\u00b3 \u274c \u2705 Node transform utilities \u2705 \u274c \u2705 <p>\u00b9 tinygltf does provide the JSON structure for extension data, but leaves the deserialization for you to do. \u00b2 fastgltf allows the user to allocate memory for buffers and images. It does not provide any mechanism for controlling all the heap allocations the library performs. \u00b3 cgltf supports sparse accessors and matrix data only with some accessor functions, but not all.</p>"},{"location":"gltf/#peformance-comparison","title":"Peformance comparison","text":"<p>Also, I don't think we should worry about performance much (comparison below). Yes, fastgltf is in theory faster (ignoring the performance cost of us hand coding image decoding). But loading isn't meant to be that quick and you can see all these loaders do quite a good job.</p> <p> https://fastgltf.readthedocs.io/latest/overview.html</p>"},{"location":"gltf/#more-on-assimp","title":"More on assimp","text":"<ul> <li>Fear of the animation API being a bit far away from the glTF animation API</li> <li>There are lots of tutorials and guides on how to use glTF animations</li> <li>https://github.com/SaschaWillems/Vulkan/blob/master/examples/gltfskinning/README.md</li> <li>Would just be easier to follow that than interfacing with assimp's animations?</li> <li>assimp pbr materials are probably decently different from glTF materials</li> <li>Again there are tutorials on how to get pbr renderers with glTF materials working</li> <li>Filament by Google is a good example of a pbr renderer using cgltf</li> <li>cgltf is one simple file</li> <li>Don't have to have the entire assimp library</li> <li>119 GitHub gltf issues for assimp</li> <li>Including: \"(partial)\" support for exporting glTF 2.0 files</li> <li>Forward axis not respected? https://github.com/assimp/assimp/issues/5330</li> <li>Can't export lights with glTF from assimp? https://github.com/assimp/assimp/issues/4155</li> <li>Can't export cameras with glTF from assimp? https://github.com/assimp/assimp/issues/3380</li> <li>https://github.com/assimp/assimp/issues/3376? Crash on Linux?</li> <li>Export to glTF 2.0 Skinning Animation model is not done correctly #2203 https://github.com/assimp/assimp/issues/2203</li> <li>assimp does not use mikktspace tangent generation which glTF recommends https://github.com/assimp/assimp/issues/2363</li> <li>Possibly broken exported glTF files</li> </ul>"},{"location":"gltf/#more-motivation","title":"More motivation","text":"<p>Take it from Sascha Willems:</p> <p>Moving to glTF</p> <p>When I started writing my first Vulkan samples glTF was still in it\u2019s infancy, esp. in terms of tooling. So I went with more common formats and went with the Open Asset importer library (Assimp) for loading these.</p> <p>But things rapidly changed with glTF 2.0, which is now pretty much and industry standard and supported by many DCC tools. And since both Vulkan and glTF are both Khronos standards this is a perfect match.</p> <p>So I decided to move away from Assimp, and started updating my Vulkan samples to use glTF instead.</p>"},{"location":"resources-notes/","title":"Resource Manager Notes","text":""},{"location":"resources-notes/#concepts-from-the-book","title":"Concepts from the book","text":"<p>The book explains we can split up resource management into:</p> <ul> <li> <p>Offline resource management and the toolchain</p> </li> <li> <p>Runtime resource management</p> </li> <li> <p>The toolchain is also called the asset/resource conditioning pipeline</p> </li> </ul> <p>The term asset conditioning pipeline is useful and I'll use it below.</p>"},{"location":"resources-notes/#how-are-we-getting-our-gltf-files","title":"How are we getting our glTF files?","text":"<p>There is a question of how we are getting our glTF files.</p> <p>There will be some premade glTF assets we can use but we will have to think about how do we create our own for the game.</p> <p>We don't have to have a fully fledged toolchain that allows for any asset created by artists to be converted to glTF but we will need some preset models to make obbys with.</p>"},{"location":"resources-notes/#augmenting-gltf-auxilliary-data","title":"Augmenting glTF? / auxilliary data?","text":"<p>One question to think about, maybe decently early, is the limitations of glTFs and what info they can store. They are quite comprehensive, but if we have a scene editor and want to create an obby with moving platforms, say the platform moves from point A to point B, how do we save out a scene representation and info about this moving platform?</p> <ul> <li>Update: for the moving platform we might be able to just store simple animations in glTF files. See https://www.khronos.org/files/gltf20-reference-guide.pdf:</li> </ul> <p>The translation, rotation and scale properties of a node may also be the target of an animation: The animation then describes how one property changes over time. The attached objects will move accordingly, allowing to model moving objects or camera flights.</p>"},{"location":"resources-notes/#packing-the-tbn-frame","title":"Packing the TBN frame","text":"<p>One obvious case for where we are going to have to have some sort of asset conditioning pipeline is for packing the TBN frame.</p> <p>The solution is:</p> <ul> <li> <p>glTFs store normals</p> </li> <li> <p>We are free to store whatever data inside these normals we like</p> </li> <li> <p>Take a normal glTF file which holds normals and tangents, calculate the TBN frame</p> </li> <li> <p>Output a new glTF file, storing the packed TBN frame into the normals, and get rid of the explicit tangents</p> </li> </ul> <p>How will we implement this though?</p>"}]}